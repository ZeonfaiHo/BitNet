{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d344348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d43426",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(r'checkpoints/bitnet_2b_4t/model_state_fp16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653a7914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tok_embeddings.weight', 'layers.0.attention.wqkv.weight', 'layers.0.attention.wo.weight', 'layers.0.attention.attn_sub_norm.weight', 'layers.0.feed_forward.w13.weight', 'layers.0.feed_forward.w2.weight', 'layers.0.feed_forward.ffn_sub_norm.weight', 'layers.0.attention_norm.weight', 'layers.0.ffn_norm.weight', 'layers.1.attention.wqkv.weight', 'layers.1.attention.wo.weight', 'layers.1.attention.attn_sub_norm.weight', 'layers.1.feed_forward.w13.weight', 'layers.1.feed_forward.w2.weight', 'layers.1.feed_forward.ffn_sub_norm.weight', 'layers.1.attention_norm.weight', 'layers.1.ffn_norm.weight', 'layers.2.attention.wqkv.weight', 'layers.2.attention.wo.weight', 'layers.2.attention.attn_sub_norm.weight', 'layers.2.feed_forward.w13.weight', 'layers.2.feed_forward.w2.weight', 'layers.2.feed_forward.ffn_sub_norm.weight', 'layers.2.attention_norm.weight', 'layers.2.ffn_norm.weight', 'layers.3.attention.wqkv.weight', 'layers.3.attention.wo.weight', 'layers.3.attention.attn_sub_norm.weight', 'layers.3.feed_forward.w13.weight', 'layers.3.feed_forward.w2.weight', 'layers.3.feed_forward.ffn_sub_norm.weight', 'layers.3.attention_norm.weight', 'layers.3.ffn_norm.weight', 'layers.4.attention.wqkv.weight', 'layers.4.attention.wo.weight', 'layers.4.attention.attn_sub_norm.weight', 'layers.4.feed_forward.w13.weight', 'layers.4.feed_forward.w2.weight', 'layers.4.feed_forward.ffn_sub_norm.weight', 'layers.4.attention_norm.weight', 'layers.4.ffn_norm.weight', 'layers.5.attention.wqkv.weight', 'layers.5.attention.wo.weight', 'layers.5.attention.attn_sub_norm.weight', 'layers.5.feed_forward.w13.weight', 'layers.5.feed_forward.w2.weight', 'layers.5.feed_forward.ffn_sub_norm.weight', 'layers.5.attention_norm.weight', 'layers.5.ffn_norm.weight', 'layers.6.attention.wqkv.weight', 'layers.6.attention.wo.weight', 'layers.6.attention.attn_sub_norm.weight', 'layers.6.feed_forward.w13.weight', 'layers.6.feed_forward.w2.weight', 'layers.6.feed_forward.ffn_sub_norm.weight', 'layers.6.attention_norm.weight', 'layers.6.ffn_norm.weight', 'layers.7.attention.wqkv.weight', 'layers.7.attention.wo.weight', 'layers.7.attention.attn_sub_norm.weight', 'layers.7.feed_forward.w13.weight', 'layers.7.feed_forward.w2.weight', 'layers.7.feed_forward.ffn_sub_norm.weight', 'layers.7.attention_norm.weight', 'layers.7.ffn_norm.weight', 'layers.8.attention.wqkv.weight', 'layers.8.attention.wo.weight', 'layers.8.attention.attn_sub_norm.weight', 'layers.8.feed_forward.w13.weight', 'layers.8.feed_forward.w2.weight', 'layers.8.feed_forward.ffn_sub_norm.weight', 'layers.8.attention_norm.weight', 'layers.8.ffn_norm.weight', 'layers.9.attention.wqkv.weight', 'layers.9.attention.wo.weight', 'layers.9.attention.attn_sub_norm.weight', 'layers.9.feed_forward.w13.weight', 'layers.9.feed_forward.w2.weight', 'layers.9.feed_forward.ffn_sub_norm.weight', 'layers.9.attention_norm.weight', 'layers.9.ffn_norm.weight', 'layers.10.attention.wqkv.weight', 'layers.10.attention.wo.weight', 'layers.10.attention.attn_sub_norm.weight', 'layers.10.feed_forward.w13.weight', 'layers.10.feed_forward.w2.weight', 'layers.10.feed_forward.ffn_sub_norm.weight', 'layers.10.attention_norm.weight', 'layers.10.ffn_norm.weight', 'layers.11.attention.wqkv.weight', 'layers.11.attention.wo.weight', 'layers.11.attention.attn_sub_norm.weight', 'layers.11.feed_forward.w13.weight', 'layers.11.feed_forward.w2.weight', 'layers.11.feed_forward.ffn_sub_norm.weight', 'layers.11.attention_norm.weight', 'layers.11.ffn_norm.weight', 'layers.12.attention.wqkv.weight', 'layers.12.attention.wo.weight', 'layers.12.attention.attn_sub_norm.weight', 'layers.12.feed_forward.w13.weight', 'layers.12.feed_forward.w2.weight', 'layers.12.feed_forward.ffn_sub_norm.weight', 'layers.12.attention_norm.weight', 'layers.12.ffn_norm.weight', 'layers.13.attention.wqkv.weight', 'layers.13.attention.wo.weight', 'layers.13.attention.attn_sub_norm.weight', 'layers.13.feed_forward.w13.weight', 'layers.13.feed_forward.w2.weight', 'layers.13.feed_forward.ffn_sub_norm.weight', 'layers.13.attention_norm.weight', 'layers.13.ffn_norm.weight', 'layers.14.attention.wqkv.weight', 'layers.14.attention.wo.weight', 'layers.14.attention.attn_sub_norm.weight', 'layers.14.feed_forward.w13.weight', 'layers.14.feed_forward.w2.weight', 'layers.14.feed_forward.ffn_sub_norm.weight', 'layers.14.attention_norm.weight', 'layers.14.ffn_norm.weight', 'layers.15.attention.wqkv.weight', 'layers.15.attention.wo.weight', 'layers.15.attention.attn_sub_norm.weight', 'layers.15.feed_forward.w13.weight', 'layers.15.feed_forward.w2.weight', 'layers.15.feed_forward.ffn_sub_norm.weight', 'layers.15.attention_norm.weight', 'layers.15.ffn_norm.weight', 'layers.16.attention.wqkv.weight', 'layers.16.attention.wo.weight', 'layers.16.attention.attn_sub_norm.weight', 'layers.16.feed_forward.w13.weight', 'layers.16.feed_forward.w2.weight', 'layers.16.feed_forward.ffn_sub_norm.weight', 'layers.16.attention_norm.weight', 'layers.16.ffn_norm.weight', 'layers.17.attention.wqkv.weight', 'layers.17.attention.wo.weight', 'layers.17.attention.attn_sub_norm.weight', 'layers.17.feed_forward.w13.weight', 'layers.17.feed_forward.w2.weight', 'layers.17.feed_forward.ffn_sub_norm.weight', 'layers.17.attention_norm.weight', 'layers.17.ffn_norm.weight', 'layers.18.attention.wqkv.weight', 'layers.18.attention.wo.weight', 'layers.18.attention.attn_sub_norm.weight', 'layers.18.feed_forward.w13.weight', 'layers.18.feed_forward.w2.weight', 'layers.18.feed_forward.ffn_sub_norm.weight', 'layers.18.attention_norm.weight', 'layers.18.ffn_norm.weight', 'layers.19.attention.wqkv.weight', 'layers.19.attention.wo.weight', 'layers.19.attention.attn_sub_norm.weight', 'layers.19.feed_forward.w13.weight', 'layers.19.feed_forward.w2.weight', 'layers.19.feed_forward.ffn_sub_norm.weight', 'layers.19.attention_norm.weight', 'layers.19.ffn_norm.weight', 'layers.20.attention.wqkv.weight', 'layers.20.attention.wo.weight', 'layers.20.attention.attn_sub_norm.weight', 'layers.20.feed_forward.w13.weight', 'layers.20.feed_forward.w2.weight', 'layers.20.feed_forward.ffn_sub_norm.weight', 'layers.20.attention_norm.weight', 'layers.20.ffn_norm.weight', 'layers.21.attention.wqkv.weight', 'layers.21.attention.wo.weight', 'layers.21.attention.attn_sub_norm.weight', 'layers.21.feed_forward.w13.weight', 'layers.21.feed_forward.w2.weight', 'layers.21.feed_forward.ffn_sub_norm.weight', 'layers.21.attention_norm.weight', 'layers.21.ffn_norm.weight', 'layers.22.attention.wqkv.weight', 'layers.22.attention.wo.weight', 'layers.22.attention.attn_sub_norm.weight', 'layers.22.feed_forward.w13.weight', 'layers.22.feed_forward.w2.weight', 'layers.22.feed_forward.ffn_sub_norm.weight', 'layers.22.attention_norm.weight', 'layers.22.ffn_norm.weight', 'layers.23.attention.wqkv.weight', 'layers.23.attention.wo.weight', 'layers.23.attention.attn_sub_norm.weight', 'layers.23.feed_forward.w13.weight', 'layers.23.feed_forward.w2.weight', 'layers.23.feed_forward.ffn_sub_norm.weight', 'layers.23.attention_norm.weight', 'layers.23.ffn_norm.weight', 'layers.24.attention.wqkv.weight', 'layers.24.attention.wo.weight', 'layers.24.attention.attn_sub_norm.weight', 'layers.24.feed_forward.w13.weight', 'layers.24.feed_forward.w2.weight', 'layers.24.feed_forward.ffn_sub_norm.weight', 'layers.24.attention_norm.weight', 'layers.24.ffn_norm.weight', 'layers.25.attention.wqkv.weight', 'layers.25.attention.wo.weight', 'layers.25.attention.attn_sub_norm.weight', 'layers.25.feed_forward.w13.weight', 'layers.25.feed_forward.w2.weight', 'layers.25.feed_forward.ffn_sub_norm.weight', 'layers.25.attention_norm.weight', 'layers.25.ffn_norm.weight', 'layers.26.attention.wqkv.weight', 'layers.26.attention.wo.weight', 'layers.26.attention.attn_sub_norm.weight', 'layers.26.feed_forward.w13.weight', 'layers.26.feed_forward.w2.weight', 'layers.26.feed_forward.ffn_sub_norm.weight', 'layers.26.attention_norm.weight', 'layers.26.ffn_norm.weight', 'layers.27.attention.wqkv.weight', 'layers.27.attention.wo.weight', 'layers.27.attention.attn_sub_norm.weight', 'layers.27.feed_forward.w13.weight', 'layers.27.feed_forward.w2.weight', 'layers.27.feed_forward.ffn_sub_norm.weight', 'layers.27.attention_norm.weight', 'layers.27.ffn_norm.weight', 'layers.28.attention.wqkv.weight', 'layers.28.attention.wo.weight', 'layers.28.attention.attn_sub_norm.weight', 'layers.28.feed_forward.w13.weight', 'layers.28.feed_forward.w2.weight', 'layers.28.feed_forward.ffn_sub_norm.weight', 'layers.28.attention_norm.weight', 'layers.28.ffn_norm.weight', 'layers.29.attention.wqkv.weight', 'layers.29.attention.wo.weight', 'layers.29.attention.attn_sub_norm.weight', 'layers.29.feed_forward.w13.weight', 'layers.29.feed_forward.w2.weight', 'layers.29.feed_forward.ffn_sub_norm.weight', 'layers.29.attention_norm.weight', 'layers.29.ffn_norm.weight', 'norm.weight', 'output.weight'])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bd6097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128256, 2560])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['tok_embeddings.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b8799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(state_dict['output.weight'], state_dict['tok_embeddings.weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca94c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_name = 'layers.0.feed_forward.w13.weight'\n",
    "# tensor_name = 'layers.0.attention.wqkv.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12519b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_before = torch.load('./checkpoints/model_state.pt')\n",
    "state_dict_after = torch.load('./checkpoints/model_state_fp16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55b51c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7734,  1.8438,  1.1562,  ..., -0.1270, -0.4160, -3.2969],\n",
       "         [ 0.1943,  0.9219,  0.7852,  ...,  1.3203, -3.1406,  0.9844],\n",
       "         [ 0.8164,  1.4453, -0.7578,  ..., -1.3594, -1.9219, -2.3750],\n",
       "         ...,\n",
       "         [-0.2139,  0.9180, -5.6562,  ...,  0.8164,  0.3457, -4.4688],\n",
       "         [-0.9336, -0.1816, -0.1030,  ...,  4.4375, -0.9062, -0.1201],\n",
       "         [ 3.4688, -3.0156, -0.9180,  ..., -0.9883,  0.9180, -1.1484]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[ 0.0000,  1.5547,  1.5547,  ..., -0.0000, -0.0000, -1.5547],\n",
       "         [ 0.0000,  1.5547,  1.5547,  ...,  1.5547, -1.5547,  1.5547],\n",
       "         [ 1.5547,  1.5547, -0.0000,  ..., -1.5547, -1.5547, -1.5547],\n",
       "         ...,\n",
       "         [-0.0000,  1.8281, -1.8281,  ...,  0.0000,  0.0000, -1.8281],\n",
       "         [-1.8281, -0.0000, -0.0000,  ...,  1.8281, -0.0000, -0.0000],\n",
       "         [ 1.8281, -1.8281, -1.8281,  ..., -1.8281,  1.8281, -1.8281]],\n",
       "        dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_before[tensor_name], state_dict_after[tensor_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad5cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_ref = torch.load('checkpoints/bitnet_2b_4t/model_state_fp16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40398251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  1.5512,  1.5512,  ..., -0.0000, -0.0000, -1.5512],\n",
       "         [ 0.0000,  1.5512,  1.5512,  ...,  1.5512, -1.5512,  1.5512],\n",
       "         [ 1.5512,  1.5512, -0.0000,  ..., -1.5512, -1.5512, -1.5512],\n",
       "         ...,\n",
       "         [-0.0000,  1.8309, -1.8309,  ...,  0.0000,  0.0000, -1.8309],\n",
       "         [-1.8309, -0.0000, -0.0000,  ...,  1.8309, -0.0000, -0.0000],\n",
       "         [ 1.8309, -1.8309, -1.8309,  ..., -1.8309,  1.8309, -1.8309]]),\n",
       " tensor([[ 0.0000,  1.5547,  1.5547,  ..., -0.0000, -0.0000, -1.5547],\n",
       "         [ 0.0000,  1.5547,  1.5547,  ...,  1.5547, -1.5547,  1.5547],\n",
       "         [ 1.5547,  1.5547, -0.0000,  ..., -1.5547, -1.5547, -1.5547],\n",
       "         ...,\n",
       "         [-0.0000,  1.8281, -1.8281,  ...,  0.0000,  0.0000, -1.8281],\n",
       "         [-1.8281, -0.0000, -0.0000,  ...,  1.8281, -0.0000, -0.0000],\n",
       "         [ 1.8281, -1.8281, -1.8281,  ..., -1.8281,  1.8281, -1.8281]],\n",
       "        dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.allclose(state_dict_ref[tensor_name], state_dict_before[tensor_name])\n",
    "state_dict_ref[tensor_name], state_dict_after[tensor_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e91661ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea9af110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors.torch\n",
    "\n",
    "\n",
    "st = safetensors.torch.load_file('checkpoints/bitnet-b1.58-2B-4T-bf16/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4beea6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1328, -0.4648,  6.4062,  ..., -2.9844, -5.5000,  0.7070],\n",
       "        [ 3.5469,  1.6016, -1.4844,  ...,  1.0703,  4.7500,  1.0781],\n",
       "        [ 9.8750,  2.2344, -5.5000,  ..., -2.4688,  1.0312, -0.7891],\n",
       "        ...,\n",
       "        [-2.2031, -2.0156, -0.4297,  ...,  0.8633,  9.9375, -3.6562],\n",
       "        [-1.0391, -1.5391, -5.9062,  ..., -1.4609, -1.1953,  7.5000],\n",
       "        [ 2.6094,  0.8984, 10.0625,  ..., -3.5469,  2.4375,  1.0547]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st['model.layers.0.mlp.down_proj.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae51e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_weight_fp16(weight):\n",
    "    s = 1.0 / weight.abs().mean().clamp_(min=1e-5)\n",
    "    new_weight = (weight * s).round().clamp(-1, 1) / s\n",
    "    return new_weight\n",
    "    # return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a9e8e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1562, -0.0000,  2.1562,  ..., -2.1562, -2.1562,  0.0000],\n",
       "        [ 2.1562,  2.1562, -2.1562,  ...,  0.0000,  2.1562,  0.0000],\n",
       "        [ 2.1562,  2.1562, -2.1562,  ..., -2.1562,  0.0000, -0.0000],\n",
       "        ...,\n",
       "        [-2.1562, -2.1562, -0.0000,  ...,  0.0000,  2.1562, -2.1562],\n",
       "        [-0.0000, -2.1562, -2.1562,  ..., -2.1562, -2.1562,  2.1562],\n",
       "        [ 2.1562,  0.0000,  2.1562,  ..., -2.1562,  2.1562,  0.0000]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_weight_fp16(st['model.layers.0.mlp.down_proj.weight'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
